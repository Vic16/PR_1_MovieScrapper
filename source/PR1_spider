{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d3bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "import pandas\n",
    "import json\n",
    "from scrapy.item import Item, Field\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Creamos la araña.\n",
    "class uoc_spider(scrapy.Spider):\n",
    "\n",
    "    # Asignamos un nombre a la araña.\n",
    "    name = \"uoc_spider\"\n",
    "\n",
    "    # Indicamos la url que queremos analizar en primer lugar.\n",
    "    start_urls = [\n",
    "        \"https://en.wikipedia.org/wiki/List_of_Academy_Award-winning_films\"\n",
    "    ]\n",
    "\n",
    "    custom_settings = {\n",
    "        'FEEDS': { 'data_wiki.json': {'format': 'json', 'overwrite': True, 'encofing':'utf-8'}}\n",
    "        }\n",
    "\n",
    "           # Definimos el analizador.\n",
    "            \n",
    "    def parse(self, response):\n",
    "        # Extraemos la info de la película\n",
    "        for name in response.xpath('//table[@class=\"wikitable sortable\"]//tr'):\n",
    "            time.sleep(random.uniform(0.20, 0.70))\n",
    "            # Capturamos las películas ganadoras\n",
    "            if name.xpath('.//b').get() is not None:\n",
    "                best_movie = True\n",
    "            else:\n",
    "                best_movie = False\n",
    "            yield {\n",
    "               'title': name.xpath('.//i//text()').get(),\n",
    "               'year': name.xpath('(.//a)[2]/text()').get(),\n",
    "               'best movie': best_movie,\n",
    "               'awards': name.xpath('(./td)[3]/text()').get(),\n",
    "               'nominations': name.xpath('(./td)[4]/text()').get(),\n",
    "               'linkMovie': str(name.xpath('.//i//a/@href').get())\n",
    "\n",
    "            }       \n",
    "        \n",
    "        # Iteramos sobre los links\n",
    "        for item in response.xpath('//table[@class = \"wikitable sortable\"]//i//a/@href'):\n",
    "            time.sleep(random.uniform(0.20, 0.70))\n",
    "            if item is not None:\n",
    "                yield response.follow(item.get(), callback=self.parse_movies)\n",
    "                \n",
    "            \n",
    "     # Capturamos la información de cada película\n",
    "    def parse_movies(self, response):\n",
    "        response_type = ['\"Directed\"', '\"Screenplay\"', \n",
    "                         '\"Starring\"', '\"Produced\"', \n",
    "                         \"'Cinematography'\", \"'Edited'\",\n",
    "                         \"'Music'\", \"'Production company'\",\n",
    "                         \"'Distributed'\", \"'Release dates'\",\n",
    "                         \"'Running time'\", \"'Country'\",\n",
    "                         \"'Language'\", \"'Budget'\",\n",
    "                         \"'Box office'\"\n",
    "                        ]\n",
    "        for tipo in response_type:\n",
    "            path_template = '//table[@class=\"infobox vevent\"]//th[contains(text(), {})]/following-sibling::td'.format(tipo)\n",
    "            if response.xpath(path_template+'//ul').get() is not None:\n",
    "                path_template = path_template+'//li'\n",
    "            for name in response.xpath(path_template):\n",
    "                yield {'movie': response.xpath('//h1[@id=\"firstHeading\"]/i/text()').get(),\n",
    "                       tipo: name.xpath('.//text()').get(),\n",
    "                       'link': response.request.url,\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "        # Links de los actores\n",
    "        path_template = '//table[@class=\"infobox vevent\"]//th[contains(text(), \"Starring\")]/following-sibling::td'\n",
    "        if response.xpath(path_template+'//ul').get() is not None:\n",
    "            path_template = path_template+'//li'\n",
    "        \n",
    "        for item in response.xpath(path_template+'//@href'):\n",
    "            if item is not None:\n",
    "                yield response.follow(item.get(), callback=self.parse_cast)\n",
    "                time.sleep(random.uniform(0.20, 0.70))\n",
    "                \n",
    "            \n",
    "     # Capturamos la información de cada persona\n",
    "    def parse_cast(self, response):\n",
    "        time.sleep(random.uniform(0.20, 0.70))\n",
    "        \n",
    "        # Loop para determinar el género de la persona\n",
    "        females_sum = 0\n",
    "        males_sum = 0\n",
    "        female_list = ['\" her \"', '\"Her \"', \n",
    "                       '\" she \"', '\"She \"', \n",
    "                       '\" female \"', \n",
    "                       '\" actress \"', \n",
    "                       '\" woman \"']\n",
    "        male_list = ['\" his \"', '\"His \"', \n",
    "                     '\" he \"', '\"He \"', \n",
    "                     '\" male \"', \n",
    "                     '\" man \"']\n",
    "\n",
    "        \n",
    "        if response.xpath('//div[@class=\"catlinks\"]//a[contains(text(), \"women\") or contains(text(), \"actresses\") or contains(text(), \"females\")]').get() is not None:\n",
    "            female = True\n",
    "        elif response.xpath('//div[@class=\"catlinks\"]//a[contains(text(), \"men\") or contains(text(), \"actors\") or contains(text(), \"males\")]').get() is not None:\n",
    "            female = False \n",
    "        else:\n",
    "            for e in response.xpath('//p'):\n",
    "                for word_fem in female_list:\n",
    "                    path = 'count(.//text()[contains(.,{})])'.format(word_fem)\n",
    "                    females_sum = females_sum + float(e.xpath(path).get())\n",
    "                    \n",
    "                for word_male in male_list:\n",
    "                    path = 'count(.//text()[contains(., {})])'.format(word_male)\n",
    "                    males_sum = males_sum + float(e.xpath(path).get())\n",
    "\n",
    "            if females_sum > males_sum:\n",
    "                female = True\n",
    "            elif females_sum < males_sum:\n",
    "                female = False\n",
    "            else:\n",
    "                female = 'NA'\n",
    "\n",
    "            \n",
    "        yield {'name': response.xpath('//table[@class=\"infobox biography vcard\"]//tr//div[@class=\"fn\"]/text()').get(),\n",
    "               'female': female,\n",
    "              'birthdate': response.xpath('//table[@class=\"infobox biography vcard\"]//tr//span[@class=\"bday\"]/text()').get(),\n",
    "               #Birthplace sale regular\n",
    "               'birthplace': response.xpath('//table[@class=\"infobox biography vcard\"]//tr//div[@class=\"birthplace\"]//text()').getall(),\n",
    "               'link': response.request.url\n",
    "              }\n",
    "                     \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "# Creamos un crawler\n",
    "  process = CrawlerProcess({'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)',\n",
    "                    'DOWNLOAD_HANDLERS': {'s3': None},\n",
    "                    'LOG_ENABLED': True\n",
    "                })\n",
    "\n",
    "# Inicializamos el crawler con nuestra araña.\n",
    "process.crawl(uoc_spider)\n",
    "\n",
    "                # Lanzamos la araña\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
